{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb86d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:17:34.329142Z",
     "iopub.status.busy": "2024-07-03T08:17:34.328793Z",
     "iopub.status.idle": "2024-07-03T08:18:08.050123Z",
     "shell.execute_reply": "2024-07-03T08:18:08.049145Z"
    },
    "papermill": {
     "duration": 33.733042,
     "end_time": "2024-07-03T08:18:08.052657",
     "exception": false,
     "start_time": "2024-07-03T08:17:34.319615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./datasets-2.14.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (1.23.5)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (11.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.3.6)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (1.5.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (4.65.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (3.2.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.70.14)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2023.6.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (3.8.4)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.16.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (6.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (3.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.3.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.4) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.4) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.14.4) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (2023.5.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.14.4) (1.16.0)\r\n",
      "Installing collected packages: datasets\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 2.1.0\r\n",
      "    Uninstalling datasets-2.1.0:\r\n",
      "      Successfully uninstalled datasets-2.1.0\r\n",
      "Successfully installed datasets-2.14.4\r\n"
     ]
    }
   ],
   "source": [
    "!cp /kaggle/input/datasets-wheel/datasets-2.14.4-py3-none-any.whl /kaggle/working\n",
    "!pip install  /kaggle/working/datasets-2.14.4-py3-none-any.whl\n",
    "# !cp /kaggle/input/backup-806/util_openbook.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f04648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:18:08.070636Z",
     "iopub.status.busy": "2024-07-03T08:18:08.070348Z",
     "iopub.status.idle": "2024-07-03T08:20:02.785745Z",
     "shell.execute_reply": "2024-07-03T08:20:02.784755Z"
    },
    "papermill": {
     "duration": 114.72691,
     "end_time": "2024-07-03T08:20:02.788183",
     "exception": false,
     "start_time": "2024-07-03T08:18:08.061273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: faiss-gpu\r\n",
      "Successfully installed faiss-gpu-1.7.2\r\n",
      "Processing ./sentence-transformers\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.30.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.65.0)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.0.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.15.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.23.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.11.1)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.2.4)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.1.99)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.16.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.12.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.6.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.6.3)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (21.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.6.3)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.3.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.16.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.1.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.5.7)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\r\n",
      "Building wheels for collected packages: sentence-transformers\r\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=126134 sha256=c91cedce04e91984d36b933e63b89a18004bd9da8be43a78a33a51f23f66c85d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6c/ea/76/d9a930b223b1d3d5d6aff69458725316b0fe205b854faf1812\r\n",
      "Successfully built sentence-transformers\r\n",
      "Installing collected packages: sentence-transformers\r\n",
      "Successfully installed sentence-transformers-2.2.2\r\n",
      "Processing /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\r\n",
      "Installing collected packages: blingfire\r\n",
      "Successfully installed blingfire-0.1.8\r\n",
      "Processing /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.30.2\r\n",
      "    Uninstalling transformers-4.30.2:\r\n",
      "      Successfully uninstalled transformers-4.30.2\r\n",
      "Successfully installed transformers-4.31.0\r\n",
      "Processing /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\r\n",
      "Installing collected packages: peft\r\n",
      "Successfully installed peft-0.4.0\r\n",
      "Processing /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl\r\n",
      "Installing collected packages: trl\r\n",
      "Successfully installed trl-0.5.0\r\n"
     ]
    }
   ],
   "source": [
    "# installing offline dependencies\n",
    "!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n",
    "!pip install -U /kaggle/working/sentence-transformers\n",
    "!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n",
    "\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f165678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:20:02.810850Z",
     "iopub.status.busy": "2024-07-03T08:20:02.810564Z",
     "iopub.status.idle": "2024-07-03T08:20:02.945465Z",
     "shell.execute_reply": "2024-07-03T08:20:02.944564Z"
    },
    "papermill": {
     "duration": 0.148745,
     "end_time": "2024-07-03T08:20:02.947577",
     "exception": false,
     "start_time": "2024-07-03T08:20:02.798832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from util_openbook import get_contexts, generate_openbook_output\n",
    "import pickle\n",
    "\n",
    "# get_contexts()\n",
    "# generate_openbook_output()\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971970c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:20:02.970103Z",
     "iopub.status.busy": "2024-07-03T08:20:02.969790Z",
     "iopub.status.idle": "2024-07-03T08:20:02.973468Z",
     "shell.execute_reply": "2024-07-03T08:20:02.972673Z"
    },
    "papermill": {
     "duration": 0.017192,
     "end_time": "2024-07-03T08:20:02.975393",
     "exception": false,
     "start_time": "2024-07-03T08:20:02.958201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# backup_model_predictions = pd.read_csv(\"submission_backup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e1a7cff",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-03T08:20:02.997173Z",
     "iopub.status.busy": "2024-07-03T08:20:02.996888Z",
     "iopub.status.idle": "2024-07-03T08:20:16.553484Z",
     "shell.execute_reply": "2024-07-03T08:20:16.552531Z"
    },
    "papermill": {
     "duration": 13.570227,
     "end_time": "2024-07-03T08:20:16.555914",
     "exception": false,
     "start_time": "2024-07-03T08:20:02.985687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from datasets import load_dataset, load_from_disk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from transformers import LongformerTokenizer, LongformerForMultipleChoice\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f939ee77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:20:16.578656Z",
     "iopub.status.busy": "2024-07-03T08:20:16.578391Z",
     "iopub.status.idle": "2024-07-03T08:20:39.189502Z",
     "shell.execute_reply": "2024-07-03T08:20:39.188193Z"
    },
    "papermill": {
     "duration": 22.625035,
     "end_time": "2024-07-03T08:20:39.191944",
     "exception": false,
     "start_time": "2024-07-03T08:20:16.566909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/stem-wiki-cohere-no-emb /kaggle/working\n",
    "!cp -r /kaggle/input/all-paraphs-parsed-expanded /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba3ce0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:20:39.215827Z",
     "iopub.status.busy": "2024-07-03T08:20:39.215507Z",
     "iopub.status.idle": "2024-07-03T08:20:39.243458Z",
     "shell.execute_reply": "2024-07-03T08:20:39.242777Z"
    },
    "papermill": {
     "duration": 0.042347,
     "end_time": "2024-07-03T08:20:39.245380",
     "exception": false,
     "start_time": "2024-07-03T08:20:39.203033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SplitList(mylist, chunk_size):\n",
    "    return [mylist[offs:offs+chunk_size] for offs in range(0, len(mylist), chunk_size)]\n",
    "\n",
    "def get_relevant_documents_parsed(df_valid):\n",
    "    df_chunk_size=600\n",
    "    paraphs_parsed_dataset = load_from_disk(\"/kaggle/working/all-paraphs-parsed-expanded\")\n",
    "    modified_texts = paraphs_parsed_dataset.map(lambda example:\n",
    "                                             {'temp_text':\n",
    "                                              f\"{example['title']} {example['section']} {example['text']}\".replace('\\n',\" \").replace(\"'\",\"\")},\n",
    "                                             num_proc=2)[\"temp_text\"]\n",
    "    \n",
    "    all_articles_indices = []\n",
    "    all_articles_values = []\n",
    "    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n",
    "        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n",
    "    \n",
    "        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n",
    "        all_articles_indices.append(articles_indices)\n",
    "        all_articles_values.append(merged_top_scores)\n",
    "        \n",
    "    article_indices_array =  np.concatenate(all_articles_indices, axis=0)\n",
    "    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n",
    "    \n",
    "    top_per_query = article_indices_array.shape[1]\n",
    "    articles_flatten = [(\n",
    "                         articles_values_array[index],\n",
    "                         paraphs_parsed_dataset[idx.item()][\"title\"],\n",
    "                         paraphs_parsed_dataset[idx.item()][\"text\"],\n",
    "                        )\n",
    "                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n",
    "    retrieved_articles = SplitList(articles_flatten, top_per_query)\n",
    "    return retrieved_articles\n",
    "\n",
    "\n",
    "\n",
    "def get_relevant_documents(df_valid):\n",
    "    df_chunk_size=800\n",
    "    \n",
    "    cohere_dataset_filtered = load_from_disk(\"/kaggle/working/stem-wiki-cohere-no-emb\")\n",
    "    modified_texts = cohere_dataset_filtered.map(lambda example:\n",
    "                                             {'temp_text':\n",
    "                                              unicodedata.normalize(\"NFKD\", f\"{example['title']} {example['text']}\").replace('\"',\"\")},\n",
    "                                             num_proc=2)[\"temp_text\"]\n",
    "    \n",
    "    all_articles_indices = []\n",
    "    all_articles_values = []\n",
    "    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n",
    "        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n",
    "    \n",
    "        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n",
    "        all_articles_indices.append(articles_indices)\n",
    "        all_articles_values.append(merged_top_scores)\n",
    "        \n",
    "    article_indices_array =  np.concatenate(all_articles_indices, axis=0)\n",
    "    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n",
    "    \n",
    "    top_per_query = article_indices_array.shape[1]\n",
    "    articles_flatten = [(\n",
    "                         articles_values_array[index],\n",
    "                         cohere_dataset_filtered[idx.item()][\"title\"],\n",
    "                         unicodedata.normalize(\"NFKD\", cohere_dataset_filtered[idx.item()][\"text\"]),\n",
    "                        )\n",
    "                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n",
    "    retrieved_articles = SplitList(articles_flatten, top_per_query)\n",
    "    return retrieved_articles\n",
    "\n",
    "\n",
    "\n",
    "def retrieval(df_valid, modified_texts):\n",
    "    \n",
    "    corpus_df_valid = df_valid.apply(lambda row:\n",
    "                                     f'{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"A\"]}\\n{row[\"B\"]}\\n{row[\"C\"]}\\n{row[\"D\"]}\\n{row[\"E\"]}',\n",
    "                                     axis=1).values\n",
    "    vectorizer1 = TfidfVectorizer(ngram_range=(1,2),\n",
    "                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n",
    "                                 stop_words=stop_words)\n",
    "    vectorizer1.fit(corpus_df_valid)\n",
    "    vocab_df_valid = vectorizer1.get_feature_names_out()\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2),\n",
    "                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n",
    "                                 stop_words=stop_words,\n",
    "                                 vocabulary=vocab_df_valid)\n",
    "    vectorizer.fit(modified_texts[:500000])\n",
    "    corpus_tf_idf = vectorizer.transform(corpus_df_valid)\n",
    "    \n",
    "    print(f\"length of vectorizer vocab is {len(vectorizer.get_feature_names_out())}\")\n",
    "\n",
    "    chunk_size = 100000\n",
    "    top_per_chunk = 10\n",
    "    top_per_query = 10\n",
    "\n",
    "    all_chunk_top_indices = []\n",
    "    all_chunk_top_values = []\n",
    "\n",
    "    for idx in tqdm(range(0, len(modified_texts), chunk_size)):\n",
    "        wiki_vectors = vectorizer.transform(modified_texts[idx: idx+chunk_size])\n",
    "        temp_scores = (corpus_tf_idf * wiki_vectors.T).toarray()\n",
    "        chunk_top_indices = temp_scores.argpartition(-top_per_chunk, axis=1)[:, -top_per_chunk:]\n",
    "        chunk_top_values = temp_scores[np.arange(temp_scores.shape[0])[:, np.newaxis], chunk_top_indices]\n",
    "\n",
    "        all_chunk_top_indices.append(chunk_top_indices + idx)\n",
    "        all_chunk_top_values.append(chunk_top_values)\n",
    "\n",
    "    top_indices_array = np.concatenate(all_chunk_top_indices, axis=1)\n",
    "    top_values_array = np.concatenate(all_chunk_top_values, axis=1)\n",
    "    \n",
    "    merged_top_scores = np.sort(top_values_array, axis=1)[:,-top_per_query:]\n",
    "    merged_top_indices = top_values_array.argsort(axis=1)[:,-top_per_query:]\n",
    "    articles_indices = top_indices_array[np.arange(top_indices_array.shape[0])[:, np.newaxis], merged_top_indices]\n",
    "    \n",
    "    return articles_indices, merged_top_scores\n",
    "\n",
    "\n",
    "def prepare_answering_input(\n",
    "        tokenizer, \n",
    "        question,  \n",
    "        options,   \n",
    "        context,   \n",
    "        max_seq_length=4096,\n",
    "    ):\n",
    "    c_plus_q   = context + ' ' + tokenizer.bos_token + ' ' + question\n",
    "    c_plus_q_4 = [c_plus_q] * len(options)\n",
    "    tokenized_examples = tokenizer(\n",
    "        c_plus_q_4, options,\n",
    "        max_length=max_seq_length,\n",
    "        padding=\"longest\",\n",
    "        truncation=False,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = tokenized_examples['input_ids'].unsqueeze(0)\n",
    "    attention_mask = tokenized_examples['attention_mask'].unsqueeze(0)\n",
    "    example_encoded = {\n",
    "        \"input_ids\": input_ids.to(model.device.index),\n",
    "        \"attention_mask\": attention_mask.to(model.device.index),\n",
    "    }\n",
    "    return example_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa732c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:20:39.268060Z",
     "iopub.status.busy": "2024-07-03T08:20:39.267812Z",
     "iopub.status.idle": "2024-07-03T08:20:39.275839Z",
     "shell.execute_reply": "2024-07-03T08:20:39.275123Z"
    },
    "papermill": {
     "duration": 0.021294,
     "end_time": "2024-07-03T08:20:39.277690",
     "exception": false,
     "start_time": "2024-07-03T08:20:39.256396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = ['each', 'you', 'the', 'use', 'used',\n",
    "                  'where', 'themselves', 'nor', \"it's\", 'how', \"don't\", 'just', 'your',\n",
    "                  'about', 'himself', 'with', \"weren't\", 'hers', \"wouldn't\", 'more', 'its', 'were',\n",
    "                  'his', 'their', 'then', 'been', 'myself', 're', 'not',\n",
    "                  'ours', 'will', 'needn', 'which', 'here', 'hadn', 'it', 'our', 'there', 'than',\n",
    "                  'most', \"couldn't\", 'both', 'some', 'for', 'up', 'couldn', \"that'll\",\n",
    "                  \"she's\", 'over', 'this', 'now', 'until', 'these', 'few', 'haven',\n",
    "                  'of', 'wouldn', 'into', 'too', 'to', 'very', 'shan', 'before', 'the', 'they',\n",
    "                  'between', \"doesn't\", 'are', 'was', 'out', 'we', 'me',\n",
    "                  'after', 'has', \"isn't\", 'have', 'such', 'should', 'yourselves', 'or', 'during', 'herself',\n",
    "                  'doing', 'in', \"shouldn't\", \"won't\", 'when', 'do', 'through', 'she',\n",
    "                  'having', 'him', \"haven't\", 'against', 'itself', 'that',\n",
    "                  'did', 'theirs', 'can', 'those',\n",
    "                  'own', 'so', 'and', 'who', \"you've\", 'yourself', 'her', 'he', 'only',\n",
    "                  'what', 'ourselves', 'again', 'had', \"you'd\", 'is', 'other',\n",
    "                  'why', 'while', 'from', 'them', 'if', 'above', 'does', 'whom',\n",
    "                  'yours', 'but', 'being', \"wasn't\", 'be']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbad2406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:20:39.300041Z",
     "iopub.status.busy": "2024-07-03T08:20:39.299772Z",
     "iopub.status.idle": "2024-07-03T08:20:39.320376Z",
     "shell.execute_reply": "2024-07-03T08:20:39.319527Z"
    },
    "papermill": {
     "duration": 0.033927,
     "end_time": "2024-07-03T08:20:39.322332",
     "exception": false,
     "start_time": "2024-07-03T08:20:39.288405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da4e1852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:20:39.345437Z",
     "iopub.status.busy": "2024-07-03T08:20:39.344760Z",
     "iopub.status.idle": "2024-07-03T08:30:15.129610Z",
     "shell.execute_reply": "2024-07-03T08:30:15.128666Z"
    },
    "papermill": {
     "duration": 575.798954,
     "end_time": "2024-07-03T08:30:15.131735",
     "exception": false,
     "start_time": "2024-07-03T08:20:39.332781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef4fbdc4dae45b08ae70d2ce1348b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2101279 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'd', 'doesn', 'don', 'isn', 'll', 's', 'shouldn', 't', 've', 'wasn', 'weren', 'won'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vectorizer vocab is 11222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/22 [00:19<06:42, 19.16s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:38<06:19, 19.00s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [00:57<06:02, 19.06s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [01:16<05:42, 19.02s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [01:35<05:22, 18.97s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [01:54<05:04, 19.02s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [02:13<04:45, 19.02s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [02:32<04:25, 19.00s/it]\u001b[A\n",
      " 41%|████      | 9/22 [02:51<04:06, 18.99s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [03:09<03:47, 18.95s/it]\u001b[A\n",
      " 50%|█████     | 11/22 [03:28<03:28, 18.96s/it]\u001b[A\n",
      " 55%|█████▍    | 12/22 [03:47<03:09, 18.97s/it]\u001b[A\n",
      " 59%|█████▉    | 13/22 [04:06<02:51, 19.00s/it]\u001b[A\n",
      " 64%|██████▎   | 14/22 [04:26<02:32, 19.03s/it]\u001b[A\n",
      " 68%|██████▊   | 15/22 [04:44<02:12, 18.94s/it]\u001b[A\n",
      " 73%|███████▎  | 16/22 [05:03<01:53, 18.99s/it]\u001b[A\n",
      " 77%|███████▋  | 17/22 [05:22<01:34, 18.97s/it]\u001b[A\n",
      " 82%|████████▏ | 18/22 [05:41<01:15, 18.96s/it]\u001b[A\n",
      " 86%|████████▋ | 19/22 [06:00<00:56, 18.92s/it]\u001b[A\n",
      " 91%|█████████ | 20/22 [06:19<00:37, 18.90s/it]\u001b[A\n",
      " 95%|█████████▌| 21/22 [06:38<00:18, 18.89s/it]\u001b[A\n",
      "100%|██████████| 22/22 [06:38<00:00, 18.12s/it]\n",
      "100%|██████████| 1/1 [08:08<00:00, 488.84s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_articles_parsed = get_relevant_documents_parsed(df_valid)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b295e432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:30:15.166024Z",
     "iopub.status.busy": "2024-07-03T08:30:15.165734Z",
     "iopub.status.idle": "2024-07-03T08:40:13.916045Z",
     "shell.execute_reply": "2024-07-03T08:40:13.915070Z"
    },
    "papermill": {
     "duration": 598.76966,
     "end_time": "2024-07-03T08:40:13.918015",
     "exception": false,
     "start_time": "2024-07-03T08:30:15.148355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09fd4909f2f480797246752274b89aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2781652 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'd', 'doesn', 'don', 'isn', 'll', 's', 'shouldn', 't', 've', 'wasn', 'weren', 'won'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vectorizer vocab is 11222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▎         | 1/28 [00:13<06:01, 13.40s/it]\u001b[A\n",
      "  7%|▋         | 2/28 [00:26<05:43, 13.20s/it]\u001b[A\n",
      " 11%|█         | 3/28 [00:39<05:25, 13.02s/it]\u001b[A\n",
      " 14%|█▍        | 4/28 [00:51<05:08, 12.84s/it]\u001b[A\n",
      " 18%|█▊        | 5/28 [01:04<04:51, 12.67s/it]\u001b[A\n",
      " 21%|██▏       | 6/28 [01:16<04:36, 12.56s/it]\u001b[A\n",
      " 25%|██▌       | 7/28 [01:28<04:22, 12.50s/it]\u001b[A\n",
      " 29%|██▊       | 8/28 [01:41<04:09, 12.47s/it]\u001b[A\n",
      " 32%|███▏      | 9/28 [01:53<03:55, 12.39s/it]\u001b[A\n",
      " 36%|███▌      | 10/28 [02:05<03:41, 12.30s/it]\u001b[A\n",
      " 39%|███▉      | 11/28 [02:17<03:29, 12.30s/it]\u001b[A\n",
      " 43%|████▎     | 12/28 [02:29<03:14, 12.16s/it]\u001b[A\n",
      " 46%|████▋     | 13/28 [02:41<03:00, 12.04s/it]\u001b[A\n",
      " 50%|█████     | 14/28 [02:53<02:47, 11.99s/it]\u001b[A\n",
      " 54%|█████▎    | 15/28 [03:05<02:35, 11.98s/it]\u001b[A\n",
      " 57%|█████▋    | 16/28 [03:17<02:22, 11.91s/it]\u001b[A\n",
      " 61%|██████    | 17/28 [03:28<02:10, 11.89s/it]\u001b[A\n",
      " 64%|██████▍   | 18/28 [03:40<01:58, 11.81s/it]\u001b[A\n",
      " 68%|██████▊   | 19/28 [03:52<01:45, 11.71s/it]\u001b[A\n",
      " 71%|███████▏  | 20/28 [04:03<01:32, 11.59s/it]\u001b[A\n",
      " 75%|███████▌  | 21/28 [04:14<01:20, 11.52s/it]\u001b[A\n",
      " 79%|███████▊  | 22/28 [04:26<01:08, 11.47s/it]\u001b[A\n",
      " 82%|████████▏ | 23/28 [04:37<00:56, 11.39s/it]\u001b[A\n",
      " 86%|████████▌ | 24/28 [04:48<00:45, 11.36s/it]\u001b[A\n",
      " 89%|████████▉ | 25/28 [04:59<00:33, 11.25s/it]\u001b[A\n",
      " 93%|█████████▎| 26/28 [05:10<00:22, 11.14s/it]\u001b[A\n",
      " 96%|█████████▋| 27/28 [05:20<00:10, 10.95s/it]\u001b[A\n",
      "100%|██████████| 28/28 [05:29<00:00, 11.75s/it]\n",
      "100%|██████████| 1/1 [06:30<00:00, 390.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_articles = get_relevant_documents(df_valid)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc908635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:40:13.967205Z",
     "iopub.status.busy": "2024-07-03T08:40:13.966877Z",
     "iopub.status.idle": "2024-07-03T08:40:14.106407Z",
     "shell.execute_reply": "2024-07-03T08:40:14.105666Z"
    },
    "papermill": {
     "duration": 0.166539,
     "end_time": "2024-07-03T08:40:14.108596",
     "exception": false,
     "start_time": "2024-07-03T08:40:13.942057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a8147a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:40:14.157619Z",
     "iopub.status.busy": "2024-07-03T08:40:14.157327Z",
     "iopub.status.idle": "2024-07-03T08:43:19.999704Z",
     "shell.execute_reply": "2024-07-03T08:43:19.998640Z"
    },
    "papermill": {
     "duration": 185.86929,
     "end_time": "2024-07-03T08:43:20.001871",
     "exception": false,
     "start_time": "2024-07-03T08:40:14.132581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:49<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/kaggle/input/last-try/checkpoints_2/checkpoint-190\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "predictions = []\n",
    "submit_ids = []\n",
    "lb_900 = []\n",
    "# prop_final = []\n",
    "\n",
    "for index in tqdm(range(df_valid.shape[0])):\n",
    "    columns = df_valid.iloc[index].values\n",
    "    submit_ids.append(columns[0])\n",
    "    question = columns[1]\n",
    "    options = [columns[2], columns[3], columns[4], columns[5], columns[6]]\n",
    "    context1 = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n",
    "    context2 = f\"{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\"\n",
    "    inputs1 = prepare_answering_input(\n",
    "        tokenizer=tokenizer, question=question,\n",
    "        options=options, context=context1,\n",
    "        )\n",
    "    inputs2 = prepare_answering_input(\n",
    "        tokenizer=tokenizer, question=question,\n",
    "        options=options, context=context2,\n",
    "        )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs1 = model(**inputs1)    \n",
    "        losses1 = -outputs1.logits[0].detach().cpu().numpy()\n",
    "        probability1 = torch.softmax(torch.tensor(-losses1), dim=-1)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        outputs2 = model(**inputs2)\n",
    "        losses2 = -outputs2.logits[0].detach().cpu().numpy()\n",
    "        probability2 = torch.softmax(torch.tensor(-losses2), dim=-1)\n",
    "        \n",
    "    probability_ = (0.35 * probability1 + 0.65 * probability2)\n",
    "    \n",
    "    lb_900.append(probability_.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9410029e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:43:20.081526Z",
     "iopub.status.busy": "2024-07-03T08:43:20.080923Z",
     "iopub.status.idle": "2024-07-03T08:43:20.161091Z",
     "shell.execute_reply": "2024-07-03T08:43:20.160369Z"
    },
    "papermill": {
     "duration": 0.12202,
     "end_time": "2024-07-03T08:43:20.162920",
     "exception": false,
     "start_time": "2024-07-03T08:43:20.040900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "normal = []\n",
    "for i in lb_900:\n",
    "    normal.append(i.tolist())\n",
    "lb_900 = torch.FloatTensor(normal)\n",
    "\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72fd4e57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:43:20.240869Z",
     "iopub.status.busy": "2024-07-03T08:43:20.240562Z",
     "iopub.status.idle": "2024-07-03T08:46:25.843682Z",
     "shell.execute_reply": "2024-07-03T08:46:25.842641Z"
    },
    "papermill": {
     "duration": 185.644737,
     "end_time": "2024-07-03T08:46:25.845979",
     "exception": false,
     "start_time": "2024-07-03T08:43:20.201242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:49<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained(\"/kaggle/input/t3-ep-1-140k/checkpoints_2/checkpoint-7500\").cuda()\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "submit_ids = []\n",
    "lb_895 = []\n",
    "# prop_final = []\n",
    "\n",
    "for index in tqdm(range(df_valid.shape[0])):\n",
    "    columns = df_valid.iloc[index].values\n",
    "    submit_ids.append(columns[0])\n",
    "    question = columns[1]\n",
    "    options = [columns[2], columns[3], columns[4], columns[5], columns[6]]\n",
    "    context1 = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n",
    "    context2 = f\"{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\"\n",
    "    inputs1 = prepare_answering_input(\n",
    "        tokenizer=tokenizer, question=question,\n",
    "        options=options, context=context1,\n",
    "        )\n",
    "    inputs2 = prepare_answering_input(\n",
    "        tokenizer=tokenizer, question=question,\n",
    "        options=options, context=context2,\n",
    "        )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs1 = model(**inputs1)    \n",
    "        losses1 = -outputs1.logits[0].detach().cpu().numpy()\n",
    "        probability1 = torch.softmax(torch.tensor(-losses1), dim=-1)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        outputs2 = model(**inputs2)\n",
    "        losses2 = -outputs2.logits[0].detach().cpu().numpy()\n",
    "        probability2 = torch.softmax(torch.tensor(-losses2), dim=-1)\n",
    "        \n",
    "    probability_ = (0.35 * probability1 + 0.65 * probability2)\n",
    "    \n",
    "    lb_895.append(probability_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6d6bb11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:46:25.953247Z",
     "iopub.status.busy": "2024-07-03T08:46:25.952920Z",
     "iopub.status.idle": "2024-07-03T08:46:26.016165Z",
     "shell.execute_reply": "2024-07-03T08:46:26.015240Z"
    },
    "papermill": {
     "duration": 0.118735,
     "end_time": "2024-07-03T08:46:26.017949",
     "exception": false,
     "start_time": "2024-07-03T08:46:25.899214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a405244b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:46:26.130657Z",
     "iopub.status.busy": "2024-07-03T08:46:26.130347Z",
     "iopub.status.idle": "2024-07-03T08:46:41.423817Z",
     "shell.execute_reply": "2024-07-03T08:46:41.422860Z"
    },
    "papermill": {
     "duration": 15.355013,
     "end_time": "2024-07-03T08:46:41.426153",
     "exception": false,
     "start_time": "2024-07-03T08:46:26.071140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerForMultipleChoice(\n",
       "  (longformer): LongformerModel(\n",
       "    (embeddings): LongformerEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (position_embeddings): Embedding(4098, 1024, padding_idx=1)\n",
       "    )\n",
       "    (encoder): LongformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (query_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): LongformerPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = LongformerTokenizer.from_pretrained(\"/kaggle/input/longformer-race-model/longformer_qa_model\")\n",
    "model = LongformerForMultipleChoice.from_pretrained(\"/kaggle/input/longformer-race-model/longformer_qa_model\").cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cba58692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:46:41.555933Z",
     "iopub.status.busy": "2024-07-03T08:46:41.555255Z",
     "iopub.status.idle": "2024-07-03T08:51:30.082128Z",
     "shell.execute_reply": "2024-07-03T08:51:30.081065Z"
    },
    "papermill": {
     "duration": 288.585885,
     "end_time": "2024-07-03T08:51:30.084872",
     "exception": false,
     "start_time": "2024-07-03T08:46:41.498987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:48<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "submit_ids = []\n",
    "\n",
    "for index in tqdm(range(df_valid.shape[0])):\n",
    "    columns = df_valid.iloc[index].values\n",
    "    submit_ids.append(columns[0])\n",
    "    question = columns[1]\n",
    "    options = [columns[2], columns[3], columns[4], columns[5], columns[6]]\n",
    "    context1 = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n",
    "    context2 = f\"{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\"\n",
    "    inputs1 = prepare_answering_input(\n",
    "        tokenizer=tokenizer, question=question,\n",
    "        options=options, context=context1,\n",
    "        )\n",
    "    inputs2 = prepare_answering_input(\n",
    "        tokenizer=tokenizer, question=question,\n",
    "        options=options, context=context2,\n",
    "        )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs1 = model(**inputs1)    \n",
    "        losses1 = -outputs1.logits[0].detach().cpu().numpy()\n",
    "        probability1 = torch.softmax(torch.tensor(-losses1), dim=-1)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        outputs2 = model(**inputs2)\n",
    "        losses2 = -outputs2.logits[0].detach().cpu().numpy()\n",
    "        probability2 = torch.softmax(torch.tensor(-losses2), dim=-1)\n",
    "        \n",
    "    probability_ = (probability1 + probability2)/2\n",
    "\n",
    "    if probability_.max() > 0.5:\n",
    "        predict = probability_\n",
    "    else:\n",
    "        predict = lb_895[index]\n",
    "    predictions.append(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e50c859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:51:30.285252Z",
     "iopub.status.busy": "2024-07-03T08:51:30.284148Z",
     "iopub.status.idle": "2024-07-03T08:51:30.378500Z",
     "shell.execute_reply": "2024-07-03T08:51:30.377747Z"
    },
    "papermill": {
     "duration": 0.167462,
     "end_time": "2024-07-03T08:51:30.380604",
     "exception": false,
     "start_time": "2024-07-03T08:51:30.213142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "normal = []\n",
    "for i in predictions:\n",
    "    normal.append(i.tolist())\n",
    "predictions = torch.FloatTensor(normal)\n",
    "\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c19ff8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:51:30.518933Z",
     "iopub.status.busy": "2024-07-03T08:51:30.518586Z",
     "iopub.status.idle": "2024-07-03T08:51:30.522906Z",
     "shell.execute_reply": "2024-07-03T08:51:30.522121Z"
    },
    "papermill": {
     "duration": 0.075431,
     "end_time": "2024-07-03T08:51:30.524817",
     "exception": false,
     "start_time": "2024-07-03T08:51:30.449386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "props = (65 * lb_900 + 35 * predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a6d432b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:51:30.663802Z",
     "iopub.status.busy": "2024-07-03T08:51:30.663496Z",
     "iopub.status.idle": "2024-07-03T08:51:30.681922Z",
     "shell.execute_reply": "2024-07-03T08:51:30.681223Z"
    },
    "papermill": {
     "duration": 0.088982,
     "end_time": "2024-07-03T08:51:30.683815",
     "exception": false,
     "start_time": "2024-07-03T08:51:30.594833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_as_ids = np.argsort(-props, 1)\n",
    "\n",
    "predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\n",
    "# predictions_as_answer_letters[:3]\n",
    "\n",
    "predictions_as_string  = [\n",
    "    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aeea736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T08:51:30.820984Z",
     "iopub.status.busy": "2024-07-03T08:51:30.820621Z",
     "iopub.status.idle": "2024-07-03T08:51:30.831371Z",
     "shell.execute_reply": "2024-07-03T08:51:30.830629Z"
    },
    "papermill": {
     "duration": 0.081438,
     "end_time": "2024-07-03T08:51:30.833202",
     "exception": false,
     "start_time": "2024-07-03T08:51:30.751764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'id':submit_ids,'prediction':predictions_as_string}).to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6169864,
     "sourceId": 54662,
     "sourceType": "competition"
    },
    {
     "datasetId": 2202288,
     "sourceId": 3680037,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2893282,
     "sourceId": 4988409,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3238926,
     "sourceId": 5632975,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3521629,
     "sourceId": 6146260,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3524699,
     "sourceId": 6146317,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3526632,
     "sourceId": 6149251,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3612472,
     "sourceId": 6282487,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3520954,
     "sourceId": 6300474,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3662908,
     "sourceId": 6359012,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3663541,
     "sourceId": 6359953,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3679312,
     "sourceId": 6383983,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3704047,
     "sourceId": 6420991,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3728231,
     "sourceId": 6456748,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3749764,
     "sourceId": 6488993,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3765051,
     "sourceId": 6511627,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3770056,
     "sourceId": 6521141,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3600418,
     "sourceId": 6572938,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3810815,
     "sourceId": 6605023,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30528,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2049.555456,
   "end_time": "2024-07-03T08:51:33.821797",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-03T08:17:24.266341",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0eab9a1bcf3a4caba8cd5d1c444d7312": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1245d4133ef44a62ac672ba104a5c556",
       "placeholder": "​",
       "style": "IPY_MODEL_ea5df322d53c4e1e9d1f0718378339ad",
       "value": "Map (num_proc=2): 100%"
      }
     },
     "1245d4133ef44a62ac672ba104a5c556": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "159a80f4c82a41e383c190276e3b92ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15da8a113572436aa5b963d9d46f5f32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "162d44f706f74af38c6827bebef2790e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1beab911bb1f49d691d494ba451b5151": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8918ecf993f34759ad7c32fd1329532a",
       "max": 2101279.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ed84ca98aee14de2a750a5090a46c61d",
       "value": 2101279.0
      }
     },
     "25020769349248b29c6f23e109be479c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_159a80f4c82a41e383c190276e3b92ce",
       "placeholder": "​",
       "style": "IPY_MODEL_15da8a113572436aa5b963d9d46f5f32",
       "value": " 2781652/2781652 [03:21&lt;00:00, 9574.10 examples/s]"
      }
     },
     "37f7620e60984a3cbbb437f5549449b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_90cfb1575d2c4c16845466c32e128043",
       "placeholder": "​",
       "style": "IPY_MODEL_70c7007dbda04f64b64a435f7517b23b",
       "value": " 2101279/2101279 [01:20&lt;00:00, 17928.83 examples/s]"
      }
     },
     "41faba32541d4841834487717b7d4896": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_162d44f706f74af38c6827bebef2790e",
       "placeholder": "​",
       "style": "IPY_MODEL_ad2821aff5b54409b001614845143cdd",
       "value": "Map (num_proc=2): 100%"
      }
     },
     "4805b238414e41e381d34bab9f17405a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64e2775742e3435f96360cee629500ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "70c7007dbda04f64b64a435f7517b23b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8918ecf993f34759ad7c32fd1329532a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ef4fbdc4dae45b08ae70d2ce1348b69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_41faba32541d4841834487717b7d4896",
        "IPY_MODEL_1beab911bb1f49d691d494ba451b5151",
        "IPY_MODEL_37f7620e60984a3cbbb437f5549449b6"
       ],
       "layout": "IPY_MODEL_4805b238414e41e381d34bab9f17405a"
      }
     },
     "90cfb1575d2c4c16845466c32e128043": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad2821aff5b54409b001614845143cdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d3cd0c17b6fe407eae90fdf4e0ab7d2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de493887c8ce4316a426a9bc978835fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d3cd0c17b6fe407eae90fdf4e0ab7d2b",
       "max": 2781652.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_64e2775742e3435f96360cee629500ef",
       "value": 2781652.0
      }
     },
     "e09fd4909f2f480797246752274b89aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0eab9a1bcf3a4caba8cd5d1c444d7312",
        "IPY_MODEL_de493887c8ce4316a426a9bc978835fe",
        "IPY_MODEL_25020769349248b29c6f23e109be479c"
       ],
       "layout": "IPY_MODEL_f40f3d0f6dd3455bbed5a8527b63e7d7"
      }
     },
     "ea5df322d53c4e1e9d1f0718378339ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ed84ca98aee14de2a750a5090a46c61d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f40f3d0f6dd3455bbed5a8527b63e7d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
